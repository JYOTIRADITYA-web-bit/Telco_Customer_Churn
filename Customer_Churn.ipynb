{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b689c63-ecf4-4002-bb51-da69e0a3fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['customer_id', 'gender', 'age', 'under_30', 'senior_citizen', 'married', 'dependents', 'number_of_dependents', 'country', 'state', 'city', 'population', 'quarter', 'referred_a_friend', 'number_of_referrals', 'tenure_in_months', 'offer', 'phone_service', 'avg_monthly_long_distance_charges', 'multiple_lines', 'internet_service', 'internet_type', 'avg_monthly_gb_download', 'online_security', 'online_backup', 'device_protection_plan', 'premium_tech_support', 'streaming_tv', 'streaming_movies', 'streaming_music', 'unlimited_data', 'contract', 'paperless_billing', 'payment_method', 'monthly_charge', 'total_charges', 'total_refunds', 'total_extra_data_charges', 'total_long_distance_charges', 'total_revenue', 'satisfaction_score', 'customer_status', 'churn_label', 'churn_score', 'cltv', 'churn_category', 'churn_reason']\n"
     ]
    }
   ],
   "source": [
    "print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fb5537-3512-42b6-834d-86eec15cb876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, columns: (7043, 50)\n",
      "  Customer ID  Gender  Age Under 30 Senior Citizen Married Dependents  \\\n",
      "0  8779-QRDMV    Male   78       No            Yes      No         No   \n",
      "1  7495-OOKFY  Female   74       No            Yes     Yes        Yes   \n",
      "2  1658-BYGOY    Male   71       No            Yes      No        Yes   \n",
      "\n",
      "   Number of Dependents        Country       State  ...  \\\n",
      "0                     0  United States  California  ...   \n",
      "1                     1  United States  California  ...   \n",
      "2                     3  United States  California  ...   \n",
      "\n",
      "  Total Extra Data Charges  Total Long Distance Charges  Total Revenue  \\\n",
      "0                       20                         0.00          59.65   \n",
      "1                        0                       390.80        1024.10   \n",
      "2                        0                       203.94        1910.88   \n",
      "\n",
      "   Satisfaction Score  Customer Status Churn Label Churn Score  CLTV  \\\n",
      "0                   3          Churned         Yes          91  5433   \n",
      "1                   3          Churned         Yes          69  5302   \n",
      "2                   2          Churned         Yes          81  3179   \n",
      "\n",
      "   Churn Category                  Churn Reason  \n",
      "0      Competitor  Competitor offered more data  \n",
      "1      Competitor  Competitor made better offer  \n",
      "2      Competitor  Competitor made better offer  \n",
      "\n",
      "[3 rows x 50 columns]\n",
      "Cleaned column names: ['customer_id', 'gender', 'age', 'under_30', 'senior_citizen', 'married', 'dependents', 'number_of_dependents', 'country', 'state']\n",
      "churn_numeric\n",
      "0    0.73463\n",
      "1    0.26537\n",
      "Name: proportion, dtype: float64\n",
      "Model dataset shape: (7043, 42)\n",
      "Train: (5634, 41) Test: (1409, 41)\n",
      "\n",
      "========== MODEL COMPARISON ==========\n",
      "\n",
      "✅ Training Logistic Regression\n",
      "Accuracy: 0.9510\n",
      "ROC AUC: 0.9915\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1035\n",
      "           1       0.89      0.93      0.91       374\n",
      "\n",
      "    accuracy                           0.95      1409\n",
      "   macro avg       0.93      0.94      0.94      1409\n",
      "weighted avg       0.95      0.95      0.95      1409\n",
      "\n",
      "\n",
      "✅ Training Random Forest\n",
      "Accuracy: 0.9446\n",
      "ROC AUC: 0.9721\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      1035\n",
      "           1       0.96      0.83      0.89       374\n",
      "\n",
      "    accuracy                           0.94      1409\n",
      "   macro avg       0.95      0.91      0.93      1409\n",
      "weighted avg       0.95      0.94      0.94      1409\n",
      "\n",
      "\n",
      "✅ Training XGBoost\n",
      "Accuracy: 0.9610\n",
      "ROC AUC: 0.9924\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1035\n",
      "           1       0.94      0.91      0.93       374\n",
      "\n",
      "    accuracy                           0.96      1409\n",
      "   macro avg       0.95      0.94      0.95      1409\n",
      "weighted avg       0.96      0.96      0.96      1409\n",
      "\n",
      "\n",
      "✅ Final XGBoost model saved as churn_xgb_pipeline.pkl\n",
      "Sample Predictions: [0 0 0 0 0]\n",
      "Sample Probabilities: [0.    0.    0.    0.001 0.   ]\n",
      "\n",
      "✅ Notebook finished — ready for Streamlit!\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Step 1 — Imports\n",
    "# ======================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ======================================================\n",
    "# Step 2 — Load Data\n",
    "# ======================================================\n",
    "df = pd.read_csv(\"telco.csv\")\n",
    "\n",
    "print(\"Rows, columns:\", df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "# ======================================================\n",
    "# Step 3 — Clean Column Names\n",
    "# ======================================================\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(' ', '_', regex=True)\n",
    "      .str.replace(r'[^\\w]', '', regex=True)\n",
    ")\n",
    "\n",
    "print(\"Cleaned column names:\", df.columns.tolist()[:10])\n",
    "\n",
    "# ======================================================\n",
    "# Step 4 — Create Target Variable\n",
    "# ======================================================\n",
    "df['churn_numeric'] = df['churn_label'].map({'Yes': 1, 'No': 0})\n",
    "print(df['churn_numeric'].value_counts(normalize=True))\n",
    "\n",
    "# ======================================================\n",
    "# Step 5 — Drop Irrelevant Columns\n",
    "# ======================================================\n",
    "drop_cols = [\n",
    "    'customer_id', 'zip_code', 'latitude', 'longitude',\n",
    "    'churn_label', 'customer_status', 'churn_score',\n",
    "    'churn_category', 'churn_reason'\n",
    "]\n",
    "\n",
    "df_model = df.drop(columns=drop_cols, errors='ignore')\n",
    "print(\"Model dataset shape:\", df_model.shape)\n",
    "\n",
    "# ======================================================\n",
    "# Step 6 — Prepare Features\n",
    "# ======================================================\n",
    "X = df_model.drop(columns=['churn_numeric'])\n",
    "y = df_model['churn_numeric']\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', cat_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# Step 7 — Train-Test Split\n",
    "# ======================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# ======================================================\n",
    "# Step 8 — Model Comparison\n",
    "# ======================================================\n",
    "results = {}\n",
    "\n",
    "print(\"\\n========== MODEL COMPARISON ==========\\n\")\n",
    "\n",
    "# ---------------- Logistic Regression ----------------\n",
    "print(\"✅ Training Logistic Regression\")\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "lr_proba = lr_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_acc = accuracy_score(y_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_test, lr_proba)\n",
    "\n",
    "print(f\"Accuracy: {lr_acc:.4f}\")\n",
    "print(f\"ROC AUC: {lr_auc:.4f}\")\n",
    "print(\"Report:\\n\", classification_report(y_test, lr_pred))\n",
    "\n",
    "results['Logistic Regression'] = (lr_acc, lr_auc)\n",
    "\n",
    "# ---------------- Random Forest ----------------\n",
    "print(\"\\n✅ Training Random Forest\")\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', RandomForestClassifier(n_estimators=300, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "rf_proba = rf_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_auc = roc_auc_score(y_test, rf_proba)\n",
    "\n",
    "print(f\"Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"ROC AUC: {rf_auc:.4f}\")\n",
    "print(\"Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "results['Random Forest'] = (rf_acc, rf_auc)\n",
    "\n",
    "# ---------------- XGBoost ----------------\n",
    "print(\"\\n✅ Training XGBoost\")\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', xgb_clf)\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "xgb_pred = xgb_pipeline.predict(X_test)\n",
    "xgb_proba = xgb_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_proba)\n",
    "\n",
    "print(f\"Accuracy: {xgb_acc:.4f}\")\n",
    "print(f\"ROC AUC: {xgb_auc:.4f}\")\n",
    "print(\"Report:\\n\", classification_report(y_test, xgb_pred))\n",
    "\n",
    "results['XGBoost'] = (xgb_acc, xgb_auc)\n",
    "\n",
    "# ======================================================\n",
    "# Step 9 — Save Best Model (XGBoost)\n",
    "# ======================================================\n",
    "print(\"\\n✅ Final XGBoost model saved as churn_xgb_pipeline.pkl\")\n",
    "joblib.dump(xgb_pipeline, \"churn_xgb_pipeline.pkl\")\n",
    "\n",
    "# ======================================================\n",
    "# Step 10 — Quick Sample Prediction\n",
    "# ======================================================\n",
    "sample = X_test.head(5)\n",
    "pred = xgb_pipeline.predict(sample)\n",
    "proba = xgb_pipeline.predict_proba(sample)[:, 1]\n",
    "\n",
    "print(\"Sample Predictions:\", pred)\n",
    "print(\"Sample Probabilities:\", np.round(proba, 3))\n",
    "\n",
    "# ======================================================\n",
    "# Notebook Complete\n",
    "# ======================================================\n",
    "print(\"\\n✅ Notebook finished — ready for Streamlit!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adba3bdc-3342-466e-9648-f85deab362ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chava\\AppData\\Local\\Temp\\ipykernel_34140\\2005369860.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['total_charges'].fillna(df['total_charges'].median(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature importance file saved: rf_feature_importance.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"telco.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "df['total_charges'] = pd.to_numeric(df['total_charges'], errors='coerce')\n",
    "df['total_charges'].fillna(df['total_charges'].median(), inplace=True)\n",
    "df['churn_label'] = df['churn_label'].map({'Yes':1, 'No':0})\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Safely remove target if present\n",
    "if \"churn_label\" in categorical_cols:\n",
    "    categorical_cols.remove(\"churn_label\")\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Create X / y\n",
    "X = df.drop(\"churn_label\", axis=1)\n",
    "y = df[\"churn_label\"]\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Extract importances\n",
    "feat_imp = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Save only the feature importance table\n",
    "pickle.dump(feat_imp, open(\"rf_feature_importance.pkl\", \"wb\"))\n",
    "\n",
    "print(\"✅ Feature importance file saved: rf_feature_importance.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a895a-6935-44a0-9be5-097db7ced7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
